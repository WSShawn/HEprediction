{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9792,"status":"ok","timestamp":1672796979217,"user":{"displayName":"Tuan Tran","userId":"13247013337371011924"},"user_tz":300},"id":"7D-ClLnDbFpR","outputId":"0c8f8e29-b465-43ad-84d6-4996bc059115"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"drive/My Drive/HEprediction\")\n","!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n","import monai\n","from monai.data import  DataLoader, ImageDataset\n","from monai.transforms import (\n","    Resize, NormalizeIntensity, Activations, Compose, EnsureType, CenterSpatialCrop,ScaleIntensity,ResizeWithPadOrCrop, ResizeWithPadOrCropd,\n","    LoadImaged, EnsureChannelFirstd, EnsureTyped, NormalizeIntensityd, ScaleIntensityd,AddChannel\n",")\n","from monai.data import CacheDataset, DataLoader, ImageDataset, Dataset\n","from monai.data import decollate_batch\n","from monai.networks.nets import DenseNet121\n","from skimage.morphology import disk, binary_dilation, binary_erosion, remove_small_objects\n","import pandas as pd\n","import numpy as np\n","import nibabel as nib\n","import torch\n","import scipy.ndimage as nd\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import nibabel.processing\n","from monai.utils import set_determinism\n","from MyDenseNet import MyDenseNet121\n","import random\n","random.seed(123)\n","set_determinism(seed=123)\n","from monai.metrics import DiceMetric\n","from monai.networks.nets import SegResNet\n","from monai.inferers import sliding_window_inference\n","from sklearn.metrics import (\n","    classification_report, confusion_matrix,\n","    ConfusionMatrixDisplay\n",")\n","VAL_AMP = True\n","def inference(input):\n","    def _compute(input):\n","        return sliding_window_inference(\n","            inputs=input,\n","            roi_size=(256, 256, 32),\n","            sw_batch_size=4,\n","            predictor=model,\n","            overlap=0.5,\n","        )\n","\n","    if VAL_AMP:\n","        with torch.cuda.amp.autocast():\n","            return _compute(input)\n","    else:\n","        return _compute(input)\n","from monai.transforms import (\n","    Activations, AsDiscrete,\n","    Compose\n",")\n","import warnings\n","warnings.filterwarnings('ignore')\n"]},{"cell_type":"code","source":["# Preprocessing for segmentation: input: CT, groundtruth; output:brain, groundtruth (512x512x48)\n","# Using only brain window\n","# Remove small objects and boundary\n","data_dir = \"italy_ds/\"\n","output_path = data_dir + \"preprocessing\"\n","raw_data = pd.read_csv(os.path.join(data_dir, \"labels.csv\"), sep=\";\")\n","for _, c_row in raw_data.iterrows():\n","    patient = str(c_row['filename'])\n","    pathCT1 = os.path.join(data_dir, \"baseline\", patient + \".nii.gz\")\n","    pathCT1seg = os.path.join(data_dir, \"mask\", patient + \"-label.nii.gz\")\n","    # load patient and extract brain window\n","    print(\"Processing: \" + patient)\n","    nii = nib.load(pathCT1seg)\n","    tmpimg1seg = np.round(nii.get_fdata()).astype(int)\n","    tmpimg1seg[tmpimg1seg != 1] = 0\n","    window_center, window_width = 40, 80\n","    nii = nib.load(pathCT1)\n","    tmpimg1 = nii.get_fdata()\n","    tmpimg1[tmpimg1 < 0] = 0\n","    tmpimg1[tmpimg1 > 200] = 0\n","    img_min = window_center - window_width // 2\n","    img_max = window_center + window_width // 2\n","    tmpimg1[tmpimg1 < img_min] = img_min\n","    tmpimg1[tmpimg1 > img_max] = img_max\n","    tmpimg1 = (tmpimg1 - tmpimg1.min()) / np.ptp(tmpimg1)\n","\n","    img1 = tmpimg1\n","    img1seg = tmpimg1seg\n","\n","    img1 = 1.0 * (img1 - img1.min()) / np.ptp(img1)\n","    img_bw = img1.copy()\n","    img_bw[img_bw > 0] = 1\n","    for slice in range(0, img_bw.shape[2]):\n","        if slice <= 2 or slice > img_bw.shape[2] - 2:\n","            img_bw[:, :, slice] = 0\n","        if img_bw[:, :, slice].sum() > 0:\n","            img_bw[:, :, slice] = binary_erosion(img_bw[:, :, slice].astype(np.uint8),\n","                                                 disk(4, dtype=bool))\n","            img_bw[:, :, slice] = remove_small_objects(img_bw[:, :, slice].astype(bool), 1000)\n","            img_bw[:, :, slice] = binary_dilation(img_bw[:, :, slice].astype(np.uint8),\n","                                                  disk(4, dtype=bool))\n","            img_bw[:, :, slice] = nd.binary_fill_holes(img_bw[:, :, slice].astype(np.uint8))\n","        if img_bw[:, :, slice].sum() > 0:\n","            mask = np.zeros(img_bw[:, :, slice].shape, dtype=np.uint8)\n","            contours = cv2.findContours(img_bw[:, :, slice].astype(np.uint8), cv2.RETR_TREE,\n","                                        cv2.CHAIN_APPROX_SIMPLE)\n","            contours = contours[0] if len(contours) == 2 else contours[1]\n","            big_contour = max(contours, key=cv2.contourArea)\n","            cv2.drawContours(mask, [big_contour], -1, (255, 255, 255), -1)\n","            img_bw[:, :, slice][mask == 0] = 0\n","            mask = np.zeros(img_bw[:, :, slice].shape, dtype=np.uint8)\n","            cv2.drawContours(mask, [big_contour], -1, (255, 255, 255), 20)\n","            img_bw[:, :, slice][mask == 255] = 0\n","    img1[img_bw == 0] = 0\n","    img1 = 1.0 * (img1 - img1.min()) / np.ptp(img1)\n","    resizeImage = ResizeWithPadOrCrop(spatial_size=(512, 512, 48))\n","    scaleImage = ScaleIntensity()\n","    if (img1.shape[0] != img1seg.shape[0] or img1.shape[1] != img1seg.shape[1] or img1.shape[2] != img1seg.shape[2]):\n","        img1_2 = np.zeros([1, img1.shape[0], img1.shape[1], img1.shape[2]])\n","        img1_2[0, :, :, :] = img1\n","        resizeSeg = ResizeWithPadOrCrop(spatial_size=(img1seg.shape[0], img1seg.shape[1], img1seg.shape[2]))\n","        img1_2 = resizeSeg(img1_2)\n","        image = np.zeros([2, img1seg.shape[0], img1seg.shape[1], img1seg.shape[2]])\n","        image[0:1, :, :, :] = img1_2\n","        image[1, :, :, :] = img1seg\n","        image = resizeImage(image)\n","    else:\n","        image = np.zeros([2, img1seg.shape[0], img1seg.shape[1], img1seg.shape[2]])\n","        image[0, :, :, :] = img1\n","        image[1, :, :, :] = img1seg\n","        image = resizeImage(image)\n","\n","    empty_header = nib.Nifti1Header()\n","    nii = nib.load(pathCT1)\n","    clipped_img = nib.Nifti1Image(image[0, :, :, :], nii.affine, empty_header)\n","    pathCT1 = os.path.join(output_path, patient + \"_brain.nii.gz\")\n","    nib.save(clipped_img, pathCT1)\n","\n","    nii = nib.load(pathCT1seg)\n","    dim = (nii.header[\"pixdim\"])[1:4]\n","    clipped_img = nib.Nifti1Image(image[1, :, :, :], nii.affine, empty_header)\n","    pathCT1seg = os.path.join(output_path, patient + \"_ich_seg.nii.gz\")\n","    nib.save(clipped_img, pathCT1seg)\n","print(\"Finish\")"],"metadata":{"id":"a7h-dJWUS6Ah","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672797033561,"user_tz":300,"elapsed":49095,"user":{"displayName":"Tuan Tran","userId":"13247013337371011924"}},"outputId":"1d875760-5201-46c5-b2e8-28dd2cda51d1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing: 10028\n","Processing: 10042\n","Processing: 10052\n","Processing: 10056\n","Processing: E106342615\n","Finish\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVJ9_n8OZSlq","outputId":"c8ec4d60-1e22-4841-ad6a-dfdbb6d96f9d","executionInfo":{"status":"ok","timestamp":1672797065982,"user_tz":300,"elapsed":28606,"user":{"displayName":"Tuan Tran","userId":"13247013337371011924"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["0. Patient:10028\n","1. Patient:10042\n","2. Patient:10052\n","3. Patient:10056\n","4. Patient:E106342615\n","Finish\n"]}],"source":["# segmentation: input: brain; output: seg_auto. Size (512x512x48)\n","# Using SegResNet\n","data_dir = \"italy_ds/\"\n","output_path=data_dir + \"preprocessing\"\n","raw_data = pd.read_csv(os.path.join(data_dir, \"labels.csv\"), sep=\";\")\n","xtest = []\n","ytest = []\n","nametest = []\n","for _, c_row in raw_data.iterrows():\n","    xtest = np.append(xtest, os.path.join(output_path, str(c_row['filename']) + \"_brain.nii.gz\"))\n","    ytest = np.append(ytest,\n","                      os.path.join(output_path, str(c_row['filename']) + \"_ich_seg.nii.gz\"))\n","    nametest = np.append(nametest, str(c_row['filename']))\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","test_transforms = Compose(\n","    [\n","        LoadImaged(keys=[\"image\", \"groundtruth\"]),\n","        EnsureChannelFirstd(keys=[\"image\", \"groundtruth\"]),\n","        EnsureTyped(keys=[\"image\", \"groundtruth\"]),\n","        NormalizeIntensityd(keys=\"image\"),\n","        ScaleIntensityd(keys=\"image\"),\n","    ]\n",")\n","test_files = [{\"image\": t2Img, \"groundtruth\": adcImg, \"name\": name} for t2Img, adcImg, name in\n","              zip(xtest, ytest, nametest)]\n","test_ds = Dataset(data=test_files, transform=test_transforms)\n","test_loader = DataLoader(test_ds, batch_size=1, shuffle=False,\n","                         num_workers=1, pin_memory=torch.cuda.is_available())\n","model = SegResNet(\n","    blocks_down=[1, 2, 2, 4],\n","    blocks_up=[1, 1, 1],\n","    init_filters=16,\n","    in_channels=1,\n","    out_channels=1,\n","    dropout_prob=0.2,\n",").to(device)\n","model.load_state_dict(\n","    torch.load(os.path.join(\"1_6000_new_best_metric_model_segmentation3d_1_1.pth\")))\n","\n","post_trans = Compose(\n","    [Activations(sigmoid=True), AsDiscrete(threshold=0.5)]\n",")\n","\n","model.eval()\n","with torch.no_grad():\n","    num = 0\n","    for val_data in test_loader:\n","        val_inputs, val_labels = (\n","            val_data[\"image\"].to(device),\n","            val_data[\"groundtruth\"].to(device),\n","        )\n","        print(str(num) + \". Patient:\" + str(val_data[\"name\"][0]))\n","        num = num + 1\n","        val_outputs = inference(val_inputs)\n","        val_outputs = post_trans(val_outputs)\n","        t1 = val_outputs[0, 0, :, :, :].cpu().numpy()\n","        nii = nib.load(os.path.join(output_path, str(val_data[\"name\"][0]) + \"_\" + \"ich_seg.nii.gz\"))\n","        empty_header = nib.Nifti1Header()\n","        affine = np.eye(4)\n","        affine[:3, :3] = np.diag((nii.header[\"pixdim\"])[1:4])\n","        pathCT1seg = os.path.join(output_path, str(val_data[\"name\"][0]) + \"_seg_auto.nii.gz\")\n","        imgseg = nib.Nifti1Image(t1, affine, empty_header)\n","        nib.save(imgseg, pathCT1seg)\n","print(\"Finish\")"]},{"cell_type":"code","source":["# preprocessing for classification (192x192x96)\n","# Working from begining again\n","# Extract brain windows, resample to (1,1,1), skull stripping, select group of slices containing Hematoma\n","# Output: _brain_seg_dilation\n","data_dir = \"italy_ds/\"\n","output_path = data_dir + \"preprocessing\"\n","raw_data = pd.read_csv(os.path.join(data_dir, \"labels.csv\"), sep=\";\")\n","xtest = []\n","ytest = []\n","nametest = []\n","for _, c_row in raw_data.iterrows():\n","    patient = str(c_row['filename'])\n","    print(\"Patient:\" + patient)\n","    pathCT1 = os.path.join(data_dir, \"baseline\", patient + \".nii.gz\")\n","    pathCT1seg = os.path.join(output_path, str(c_row['filename']) + \"_seg_auto.nii.gz\")\n","    nii = nib.load(pathCT1seg)\n","    print(\"Original\")\n","    print(nii.get_fdata().shape)\n","    tmp = (nii.header[\"pixdim\"])[1:4]\n","    print(nii.header[\"pixdim\"])\n","    image = nii.get_fdata()\n","\n","    voxel_size = [1, 1, 1]\n","    tmpimg1seg = np.round(nii.get_fdata()).astype(int)\n","    tmpimg1seg[tmpimg1seg != 1] = 0\n","\n","    affine = np.eye(4)\n","    affine[:3, :3] = np.diag((nii.header[\"pixdim\"])[1:4])\n","    pathtmp = os.path.join(data_dir, \"1tmp_brain_seg.nii.gz\")\n","    empty_header = nib.Nifti1Header()\n","    clipped_img = nib.Nifti1Image(tmpimg1seg, affine, empty_header)\n","    nib.save(clipped_img, pathtmp)\n","    nii = nib.load(pathtmp)\n","    nii = nibabel.processing.resample_to_output(nii, voxel_size)\n","    tmpimg1seg = np.round(nii.get_fdata()).astype(int)\n","    tmpimg1seg[tmpimg1seg > 0] = 1\n","\n","    # load bone window and resample\n","    window_center, window_width = 40, 80\n","    nii = nib.load(pathCT1)\n","    tmpimg1 = nii.get_fdata()\n","    tmpimg1[tmpimg1 < 0] = 0\n","    tmpimg1[tmpimg1 > 200] = 0\n","    resizeImage = ResizeWithPadOrCrop(spatial_size=(512, 512, 48))\n","    addChannel = AddChannel()\n","    image = resizeImage(addChannel(tmpimg1))\n","    tmpimg1 = image[0, :, :, :]\n","\n","    pathtmp = os.path.join(data_dir, \"3tmp_brain_seg.nii.gz\")\n","    empty_header = nib.Nifti1Header()\n","    clipped_img = nib.Nifti1Image(tmpimg1, affine, empty_header)\n","    nib.save(clipped_img, pathtmp)\n","    nii = nib.load(pathtmp)\n","    nii = nibabel.processing.resample_to_output(nii, voxel_size)\n","    tmpimg1 = nii.get_fdata()\n","    img_min = window_center - window_width // 2\n","    img_max = window_center + window_width // 2\n","    tmpimg1[tmpimg1 < img_min] = img_min\n","    tmpimg1[tmpimg1 > img_max] = img_max\n","    tmpimg1 = (tmpimg1 - tmpimg1.min()) / np.ptp(tmpimg1)\n","    img_bw = tmpimg1.copy()\n","    img_bw[img_bw > 0] = 1\n","    for slice in range(0, img_bw.shape[2]):\n","        if img_bw[:, :, slice].sum() > 0:\n","            img_bw[:, :, slice] = binary_erosion(img_bw[:, :, slice].astype(np.uint8),\n","                                                 disk(4, dtype=bool))\n","            img_bw[:, :, slice] = remove_small_objects(img_bw[:, :, slice].astype(bool), 1000)\n","            img_bw[:, :, slice] = binary_dilation(img_bw[:, :, slice].astype(np.uint8),\n","                                                  disk(4, dtype=bool))\n","            img_bw[:, :, slice] = nd.binary_fill_holes(img_bw[:, :, slice].astype(np.uint8))\n","        if img_bw[:, :, slice].sum() > 0:\n","            mask = np.zeros(img_bw[:, :, slice].shape, dtype=np.uint8)\n","            contours = cv2.findContours(img_bw[:, :, slice].astype(np.uint8), cv2.RETR_TREE,\n","                                        cv2.CHAIN_APPROX_SIMPLE)\n","            contours = contours[0] if len(contours) == 2 else contours[1]\n","            big_contour = max(contours, key=cv2.contourArea)\n","            cv2.drawContours(mask, [big_contour], -1, (255, 255, 255), -1)\n","            img_bw[:, :, slice][mask == 0] = 0\n","            mask = np.zeros(img_bw[:, :, slice].shape, dtype=np.uint8)\n","            cv2.drawContours(mask, [big_contour], -1, (255, 255, 255), 20)\n","            img_bw[:, :, slice][mask == 255] = 0\n","    tmpimg1[img_bw == 0] = 0\n","    tmpimg1 = 1.0 * (tmpimg1 - tmpimg1.min()) / np.ptp(tmpimg1)\n","\n","    # find the first slice which contains hematoma\n","    for slice1 in range(tmpimg1seg.shape[2]):\n","        if tmpimg1seg[:, :, slice1].sum() > 0:\n","            break\n","    # find the last slice which contains hematoma\n","    for slice2 in range(tmpimg1seg.shape[2] - 1, 0, -1):\n","        if tmpimg1seg[:, :, slice2].sum() > 0:\n","            break\n","    if slice1 < slice2:\n","        slice1 = slice1 - 16\n","        if slice1 < 0:\n","            slice1 = 0\n","        slice2 = slice2 + 16\n","        if slice2 > tmpimg1seg.shape[2] - 1:\n","            slice2 = tmpimg1seg.shape[2] - 1\n","        if slice2 - slice1 >= 96:\n","            slice2 = slice1 + 96\n","        img1 = np.zeros([tmpimg1.shape[0], tmpimg1.shape[1], 96])\n","        img1seg = np.zeros([tmpimg1seg.shape[0], tmpimg1seg.shape[1], 96])\n","        img1[:, :, 0:slice2 - slice1] = tmpimg1[:, :, slice1:slice2]\n","        img1seg[:, :, 0:slice2 - slice1] = tmpimg1seg[:, :, slice1:slice2]\n","    else:\n","        img1 = np.zeros([tmpimg1.shape[0], tmpimg1.shape[1], 96])\n","        img1[:, :, 0:64] = tmpimg1[:, :,\n","                           int(np.round(tmpimg1.shape[2] / 2) - 32):int(np.round(tmpimg1.shape[2] / 2) + 32)]\n","        img1seg = np.zeros([tmpimg1seg.shape[0], tmpimg1seg.shape[1], 96])\n","\n","    img1 = 1.0 * (img1 - img1.min()) / np.ptp(img1)\n","\n","    img1dilation = img1.copy()\n","    img_bw = img1seg.copy()\n","    for slice in range(0, img_bw.shape[2]):\n","        if img_bw[:, :, slice].sum() > 0:\n","            img_bw[:, :, slice] = binary_dilation(img_bw[:, :, slice].astype(np.uint8),\n","                                                  disk(40, dtype=bool))\n","    img1dilation[img_bw == 0] = 0\n","\n","    image = np.zeros([2, img1.shape[0], img1.shape[1], img1.shape[2]])\n","    image[0, :, :, :] = img1\n","    image[1, :, :, :] = img1dilation\n","    resizeImage = Resize([192, 192, 96])\n","    cropImage = CenterSpatialCrop(roi_size=(128, 128, 96))\n","    scaleImage = ScaleIntensity()\n","    image = resizeImage(image)\n","    image = cropImage(image)\n","    image = scaleImage(image)\n","    # save file\n","    pathCT1clipseg = os.path.join(data_dir, \"classification\", patient + \"_brain_seg_dilation.nii.gz\")\n","    empty_header = nib.Nifti1Header()\n","    nii = nib.load(pathCT1)\n","    clipped_img = nib.Nifti1Image(image, nii.affine, empty_header)\n","    nib.save(clipped_img, pathCT1clipseg)\n","\n","    image = np.zeros([2, img1.shape[0], img1.shape[1], img1.shape[2]])\n","    image[0, :, :, :] = img1\n","    image[1, :, :, :] = img1seg\n","    image = resizeImage(image)\n","    image = cropImage(image)\n","    image = scaleImage(image)\n","\n","    # save file if you want to use without dilation\n","    pathCT1clipseg = os.path.join(data_dir, \"classification\", patient + \"_brain_seg.nii.gz\")\n","    clipped_img = nib.Nifti1Image(image, nii.affine, empty_header)\n","    nib.save(clipped_img, pathCT1clipseg)\n"],"metadata":{"id":"RAy9P3MnykwL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672797250525,"user_tz":300,"elapsed":178482,"user":{"displayName":"Tuan Tran","userId":"13247013337371011924"}},"outputId":"a7d6fd1b-a850-4b75-b21e-e66102c7c3ff"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Patient:10028\n","Original\n","(512, 512, 48)\n","[1.      0.46875 0.46875 5.      1.      1.      1.      1.     ]\n","Patient:10042\n","Original\n","(512, 512, 48)\n","[1.        0.488281  0.5701952 4.5675735 1.        1.        1.\n"," 1.       ]\n","Patient:10052\n","Original\n","(512, 512, 48)\n","[1.         0.48828125 0.48828125 3.         1.         1.\n"," 1.         1.        ]\n","Patient:10056\n","Original\n","(512, 512, 48)\n","[1.       0.488281 0.488281 5.       1.       1.       1.       1.      ]\n","Patient:E106342615\n","Original\n","(512, 512, 48)\n","[1.         0.474609   0.47460908 3.682628   1.         1.\n"," 1.         1.        ]\n"]}]},{"cell_type":"code","source":["#Classification using MyDenseNet121 (input: 2x128x128x96)\n","root_dir = \"italy_ds/\"\n","data_dir = os.path.join(root_dir, \"classification\")\n","raw_data = pd.read_csv(os.path.join(root_dir, \"labels.csv\"), sep=\";\")\n","pathFilenames = []\n","labels = []\n","names = []\n","for _, c_row in raw_data.iterrows():\n","    pathFilenames.append(os.path.join(data_dir, str(c_row['filename']) + \"_brain_seg_dilation.nii.gz\"))\n","    labels.append(c_row['label'])\n","    names.append(str(c_row['filename']))\n","labels = np.asarray(labels).astype(int)\n","pathFilenames = np.asarray(pathFilenames)\n","names = np.asarray(names)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = MyDenseNet121(spatial_dims=3, in_channels=2, out_channels=128, dropout_prob=0.2).to(device)\n","model.cuda()\n","model.load_state_dict(torch.load(\"96dilation_test_best_metric_model_classification3d_11.pth\"))\n","model.eval()\n","xval = pathFilenames\n","yval = labels\n","val_ds = ImageDataset(\n","    image_files=xval, labels=yval)\n","val_loader = DataLoader(val_ds, batch_size=1, shuffle=False,\n","                        num_workers=1, pin_memory=torch.cuda.is_available())\n","y_pred_trans = Compose([EnsureType(), Activations(sigmoid=True)])\n","y_trans = Compose([EnsureType()])\n","with torch.no_grad():\n","    y_pred = torch.tensor([], dtype=torch.float32, device=device)\n","    y = torch.tensor([], dtype=torch.double, device=device)\n","    for val_data in val_loader:\n","        inputs, val_labels = val_data[0].to(\n","            device), val_data[1].to(device)\n","        val_outputs = model(inputs)\n","        y_pred1 = val_outputs.flatten()\n","        y1 = val_labels\n","        y_pred = torch.cat([y_pred, y_pred1], dim=0)\n","        y = torch.cat([y, y1], dim=0)\n","    y_onehot = [y_trans(i) for i in decollate_batch(y)]\n","    y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n","    auc_metric1 = monai.metrics.ROCAUCMetric()\n","    auc_metric1(y_pred_act, y_onehot)\n","    print(\"AUC total= \")\n","    print(auc_metric1.aggregate())\n","    auc_metric1.reset()\n"],"metadata":{"id":"4Up055RkynrM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672797265256,"user_tz":300,"elapsed":3534,"user":{"displayName":"Tuan Tran","userId":"13247013337371011924"}},"outputId":"a21dc988-3d75-44c2-e61c-3959c8417e6f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["AUC total= \n","0.8333333333333334\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1WSmJAGEuG1UKaw2gijvNeKBDFAIgsCxI","timestamp":1648200209441}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}